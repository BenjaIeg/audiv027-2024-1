# clase-06

## entrega: título

integrantes: Benjamín Espinoza, Diego Lopez, Giovanni Torres

fecha 19-04-2024

## Ideas

Realizar un control o joystick a base gestos de webcam, ya sea con la mano o con poses

o

Realizar un analizador de buen canto-mal canto

## materiales

este trabajo lo hice con los siguientes materiales:

- p5.js en su versión x.y.z disponible en la web (POSIBLEMENTE SEA UNA BUENA ALTERNATIVA PARA EL ENTRENAMIENTO Y RECONOCIMIENTO DE GESTOS)
- [Markdown para escribir la documentación de este archivo](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#h1)
- la base de datos en Probablemente exploraremos las alternativas que nos entrega TEachable Machine
- Wekinator escrito por X y disponible en
- Navegador Mozilla Firefox en su versión x.y.z
- Micrófono o webcam dependiendo de que idea de proyecto elijamos

## Documentacion, bitacora

Con la primera idea en mente, se buscaron tutoriales y codigos abiertos en internet de gente que haya hecho proyectos similares, ya sea por pose o ya sea reconocimiento de gestos y eso traducirlo en acciones en tiempo real

Se comprobo la capacidad de teachable machine de reconocer especificamente poses de "patada", "puño" y "parado", lo cual si bien con simples puños si lo reconocia, al momento de alzar la pierna en posicion de patada, este no podia reconocer las piernas, posicionandola de manera incoherente con respecto a lo que presento la webcam.

![324118065-9bb7f1dd-1d3c-4d49-8a5b-6edb2eaa158a](https://github.com/BenjaIeg/audiv027-2024-1/assets/128185999/1bbeb8d0-5389-4873-8c43-9c83565e19f4)

![324118148-1fc7c549-0cbb-4a17-8ddc-acb6a92370c9](https://github.com/BenjaIeg/audiv027-2024-1/assets/128185999/06649939-c1f1-4cb9-abf5-b20333e6c64b)

![324118184-63511a8b-738b-48ef-905b-c6932b81c122](https://github.com/BenjaIeg/audiv027-2024-1/assets/128185999/3f3b08fc-e2a4-4d84-8656-a882e1bca67f)

![324118219-a867bd91-873d-4ec9-ad0a-b553e3cea02b](https://github.com/BenjaIeg/audiv027-2024-1/assets/128185999/6c483a64-b087-4177-8b1b-adfebb675005)


El siguiente link
https://teachablemachine.withgoogle.com/models/4hGtLV8sq/

## código

el código está subido en esta misma carpeta, y en el editor de p5.js, etc.

## capturas de pantalla

u otro material multimedia

## conclusiones

en este trabajo aprendí.....

## citas y referentes

[Video Turning My Body Into a Controller with Machine Learning, ml5.js, and p5.js](https://www.youtube.com/watch?v=96sWFP9CCkQ)

[Video  I made a full-body GAME controller](https://www.youtube.com/watch?v=Vi3Li3TkUVY)

[Codigo abierto Full body game controler](https://github.com/everythingishacked/Gamebody)

[Entrenamiento de reconocimiento de gestos de mano](https://editor.p5js.org/AndreasRef/sketches/vyiGyVon9)

[Clasificacion de poses con ml5](https://www.youtube.com/watch?v=FYgYyq-xqAw)
